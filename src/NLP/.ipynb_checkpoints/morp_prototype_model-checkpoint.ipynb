{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T05:55:40.703278Z",
     "start_time": "2019-08-07T05:55:28.277612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chan 2019-08-07 \n",
      "\n",
      "CPython 3.7.3\n",
      "IPython 7.6.1\n",
      "\n",
      "numpy 1.16.4\n",
      "pandas 0.24.2\n",
      "sklearn 0.21.2\n",
      "konlpy 0.5.1\n",
      "tensorflow 1.13.1\n",
      "matplotlib 3.1.0\n",
      "imblearn 0.5.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a Chan -d -v -p numpy,pandas,sklearn,konlpy,tensorflow,matplotlib,imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T05:55:41.525446Z",
     "start_time": "2019-08-07T05:55:40.709275Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from konlpy.tag import Okt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T05:55:41.715339Z",
     "start_time": "2019-08-07T05:55:41.530445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>자기잘못인거알면 중고딩도 먼저사과하는걸아는데</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>싹둑이 채팅창 관리 중입니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>싹둑이 채팅창 관리 중입니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>어제 어글 아직도 가? 개인적으로 사과하셨대 그만해 칭구들앙</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>케읍이 뭔데요 무슨사건있엇음?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 chat  label\n",
       "0            자기잘못인거알면 중고딩도 먼저사과하는걸아는데      0\n",
       "1                     싹둑이 채팅창 관리 중입니다      0\n",
       "2                     싹둑이 채팅창 관리 중입니다      0\n",
       "3  어제 어글 아직도 가? 개인적으로 사과하셨대 그만해 칭구들앙       0\n",
       "4                    케읍이 뭔데요 무슨사건있엇음?      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = pd.DataFrame()\n",
    "for i in range(1,5):\n",
    "    print(i)\n",
    "    dump = pd.read_csv(\"../../data/sample ({}).csv\".format(i), engine='python',names=['chat','label'])\n",
    "    datasets = pd.concat([datasets, dump])\n",
    "datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T05:55:41.731334Z",
     "start_time": "2019-08-07T05:55:41.723335Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T05:55:41.774305Z",
     "start_time": "2019-08-07T05:55:41.739328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3500 entries, 0 to 3499\n",
      "Data columns (total 2 columns):\n",
      "chat     3500 non-null object\n",
      "label    3500 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 54.8+ KB\n"
     ]
    }
   ],
   "source": [
    "datasets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T05:55:41.799291Z",
     "start_time": "2019-08-07T05:55:41.779303Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets.label = datasets.label.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T05:55:41.834271Z",
     "start_time": "2019-08-07T05:55:41.805289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16163292399601725"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets[datasets.label ==1])/ len(datasets[datasets.label ==0]) # 유해한 레이블의 데이터가 많이 부족함 데이터 편향ㅠㅠ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T15:38:19.687895Z",
     "start_time": "2019-08-06T15:38:19.677899Z"
    }
   },
   "source": [
    "# Tokenize\n",
    "## 형태소분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T05:55:42.671439Z",
     "start_time": "2019-08-07T05:55:41.843268Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skarn\\Anaconda3\\envs\\DataAnalysis\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "morp = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.353Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                    | 0/3500 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "morped = [morp.pos(_, norm=True, join=True) for _ in tqdm(datasets.chat)] # Stemming은 하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.360Z"
    }
   },
   "outputs": [],
   "source": [
    "morped[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary\n",
    "최빈 형태소에 대한 단어사전 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.369Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "\n",
    "pad_id = 0\n",
    "oov_id = 1\n",
    "index_offset = 1\n",
    "\n",
    "def make_vocab(sentences):\n",
    "    word_counter = Counter()\n",
    "\n",
    "    for sent in sentences:\n",
    "        word_counter.update(sent)\n",
    "\n",
    "    most_common = word_counter.most_common()\n",
    "    print(\"고빈도 단어:\")\n",
    "    for k, v in most_common[:10]:\n",
    "        print(k, \": \", v)\n",
    "\n",
    "        vocab = {\n",
    "        '<PAD>': pad_id,\n",
    "        '<OOV>': oov_id\n",
    "        }\n",
    "    for i, (word, cnt) in enumerate(most_common, start=index_offset+1):\n",
    "        vocab[word] = i\n",
    "        if len(vocab) >= vocab_size:\n",
    "            break\n",
    "\n",
    "    return vocab\n",
    "\n",
    "word_index = make_vocab(morped)\n",
    "word_inverted_index = {v:k for k, v in word_index.items()}\n",
    "\n",
    "print(\"\\n단어 사전:\")\n",
    "for i in range(0, 10):\n",
    "    print(i, word_inverted_index[i])\n",
    "\n",
    "print(\"\\n단어 사전 크기: \", len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.375Z"
    }
   },
   "outputs": [],
   "source": [
    "def index_to_text(indexes):\n",
    "    return ' '.join([word_inverted_index[i] for i in indexes])\n",
    "\n",
    "def text_to_index(tokens):\n",
    "    indexes = []\n",
    "    for tok in tokens:\n",
    "        if tok in word_index:\n",
    "            indexes.append(word_index[tok])\n",
    "        else:\n",
    "            indexes.append(oov_id)\n",
    "\n",
    "    return indexes\n",
    "\n",
    "print(\"원본: \", morped[0])\n",
    "ids = text_to_index(morped[0])\n",
    "print(\"문자 -> 숫자: \", ids)\n",
    "print(\"숫자 -> 문자: \", index_to_text(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.382Z"
    }
   },
   "outputs": [],
   "source": [
    "x_variable = [text_to_index(_) for _ in morped]\n",
    "\n",
    "sentence_size = 20\n",
    "x_padded = sequence.pad_sequences(x_variable,\n",
    "                                 maxlen=sentence_size,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=pad_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.394Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_padded, datasets.label)\n",
    "\n",
    "print(\"train_inputs shape: \", X_train.shape)\n",
    "print(\"test_inputs shape: \", X_test.shape)\n",
    "print(\"train_labels shape: \", y_train.shape)\n",
    "print(\"test_labels shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.404Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.412Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, 10),\n",
    "    keras.layers.Conv1D(32, 3, padding=\"same\", activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Conv1D(32, 3, padding=\"same\", activation=tf.nn.relu),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(2, activation=tf.nn.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.418Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    val = plt.plot(history.epoch, history.history['val_loss'],\n",
    "                 '--', label='Test')\n",
    "    plt.plot(history.epoch, history.history['loss'], color=val[0].get_color(),\n",
    "           label='Train')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlim([0,max(history.epoch)])\n",
    "\n",
    "def eval_model(model):\n",
    "    test_loss, test_acc = model.evaluate(X_test, pd.get_dummies(y_test))\n",
    "    print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.431Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "          pd.get_dummies(y_train),\n",
    "          epochs=5,\n",
    "          validation_data=(X_test, pd.get_dummies(y_test))\n",
    "         )\n",
    "plot_loss(history)\n",
    "eval_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.438Z"
    }
   },
   "outputs": [],
   "source": [
    "set(model.predict_classes(X_test)) ## 전부 0으로 예측을 함 . 데이터 불균형 문제때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.445Z"
    }
   },
   "outputs": [],
   "source": [
    "# result = pd.DataFrame(np.apply_along_axis(index_to_text, 1, X_test))\n",
    "# result['predict'] = model.predict_proba(X_test)[:,1] # 유해하다고 판별할 확률\n",
    "# result[result.predict>0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 데이터 클래스 불균형 문제 해결하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.451Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upsampling\n",
    "- 딥러닝은 데이터가 많을수록 좋다.\n",
    "- 보다 많은 데이터 사용을 위해 upsampling을 사용하자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.456Z"
    }
   },
   "outputs": [],
   "source": [
    "up_X, up_y = RandomOverSampler().fit_resample(x_padded, datasets.label)\n",
    "up_X_train, up_X_test, up_y_train, up_y_test = train_test_split(up_X, up_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.462Z"
    }
   },
   "outputs": [],
   "source": [
    "# 총 데이터 수 , 1 레이블 데이터 수\n",
    "len(up_y), up_y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.472Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(up_X_train,\n",
    "          pd.get_dummies(up_y_train),\n",
    "          epochs=5,\n",
    "          validation_data=(up_X_test, pd.get_dummies(up_y_test))\n",
    "         )\n",
    "plot_loss(history)\n",
    "test_loss, test_acc = model.evaluate(up_X_test, pd.get_dummies(up_y_test))\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.482Z"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(np.apply_along_axis(index_to_text, 1, up_X_test))\n",
    "result['predict'] = model.predict_proba(up_X_test)[:,1] # 유해하다고 판별할 확률\n",
    "print('전체채팅수{}, 유해채팅수{}'.format(len(result),len(result[result.predict>0.5])))\n",
    "result[result.predict>0.5].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.495Z"
    }
   },
   "outputs": [],
   "source": [
    "result.to_csv('../../data/cnn_result.csv', encoding='utf-16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류 애매한 채팅들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.509Z"
    }
   },
   "outputs": [],
   "source": [
    "result[(result.predict>0.1) & (result.predict<0.9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 실패한 채팅들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.520Z"
    }
   },
   "outputs": [],
   "source": [
    "result['label'] = up_y_test\n",
    "result[model.predict_classes(up_X_test) != up_y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시11111발 의 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.527Z"
    }
   },
   "outputs": [],
   "source": [
    "test_chat = \"시1111발\"\n",
    "test_id = text_to_index(morp.pos(test_chat, norm=True, join=True))\n",
    "print(morp.pos(test_chat, norm=True, join=True))\n",
    "sentence_size = 20\n",
    "x_padded = sequence.pad_sequences([test_id],\n",
    "                                 maxlen=sentence_size,\n",
    "                                 truncating='post',\n",
    "                                 padding='post',\n",
    "                                 value=pad_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-07T05:55:28.534Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(x_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- 형태소별 Tokenize 말고 한글 자모별 Tokenize 하여 실험해보기\n",
    "- CNN layer / Parameter 변경시켜보기\n",
    "- 예측 결과 검정하기\n",
    "    - Attention 이용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
